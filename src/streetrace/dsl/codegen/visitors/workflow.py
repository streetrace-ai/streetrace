"""Workflow visitor for DSL code generation.

Generate the main Python workflow class structure.
"""

from streetrace.dsl.ast.nodes import (
    AgentDef,
    DslFile,
    EventHandler,
    FlowDef,
    ModelDef,
    PromptDef,
    SchemaDef,
    ToolDef,
    TypeExpr,
)
from streetrace.dsl.codegen.emitter import CodeEmitter
from streetrace.dsl.codegen.visitors.flows import FlowVisitor
from streetrace.dsl.codegen.visitors.handlers import HandlerVisitor
from streetrace.log import get_logger

logger = get_logger(__name__)

# Header comment for generated code
GENERATED_HEADER = '''"""Generated workflow from {source_file}.

Auto-generated by Streetrace DSL Compiler.
Do not edit directly - modify the .sr source file instead.
"""

'''

# Required imports for generated code
IMPORTS = """from collections.abc import AsyncGenerator
from typing import Any

import asyncio

from google.adk.events import Event

from streetrace.dsl.runtime.context import WorkflowContext
from streetrace.dsl.runtime.events import FlowEvent
from streetrace.dsl.runtime.workflow import (
    DslAgentWorkflow,
    EscalationSpec,
    PromptSpec,
)
from streetrace.dsl.runtime.errors import (
    AbortError,
    BlockedInputError,
    RetryInputError,
    RetryStepError,
)
from streetrace.dsl.runtime.utils import list_concat, normalized_equals

"""


class WorkflowVisitor:
    """Generate the main Python workflow class structure.

    Visit the DSL file AST and emit a complete Python module
    containing the workflow class with all definitions.
    """

    def __init__(self, emitter: CodeEmitter) -> None:
        """Initialize the workflow visitor.

        Args:
            emitter: Code emitter for output generation.

        """
        self._emitter = emitter
        self._models: list[ModelDef] = []
        self._prompts: list[PromptDef] = []
        self._tools: list[ToolDef] = []
        self._schemas: list[SchemaDef] = []
        self._agents: list[AgentDef] = []
        self._flows: list[FlowDef] = []
        self._handlers: list[EventHandler] = []

    def visit(
        self,
        node: DslFile,
        source_file: str,
        *,
        merged_prompts: dict[str, PromptDef] | None = None,
    ) -> None:
        """Visit a DSL file and generate the complete workflow class.

        Args:
            node: DSL file AST node.
            source_file: Name of the source file.
            merged_prompts: Optional dict of merged prompts from semantic analysis.
                When provided, these are used instead of extracting prompts from
                AST statements. This ensures prompt override/merge semantics work.

        """
        # Collect all definitions
        self._collect_definitions(node, merged_prompts=merged_prompts)

        # Emit header and imports
        self._emit_header(source_file)
        self._emit_imports()

        # Emit the workflow class
        self._emit_class_definition(source_file)

    def _collect_definitions(
        self,
        node: DslFile,
        *,
        merged_prompts: dict[str, PromptDef] | None = None,
    ) -> None:
        """Collect all definitions from the AST.

        Args:
            node: DSL file AST node.
            merged_prompts: Optional dict of merged prompts from semantic analysis.

        """
        type_dispatch: dict[type, list] = {  # type: ignore[type-arg]
            ModelDef: self._models,
            ToolDef: self._tools,
            SchemaDef: self._schemas,
            AgentDef: self._agents,
            FlowDef: self._flows,
            EventHandler: self._handlers,
        }
        for stmt in node.statements:
            target = type_dispatch.get(type(stmt))
            if target is not None:
                target.append(stmt)
            elif isinstance(stmt, PromptDef) and merged_prompts is None:
                self._prompts.append(stmt)

        # Use merged prompts if provided (from semantic analysis)
        if merged_prompts is not None:
            self._prompts = list(merged_prompts.values())

    def _emit_header(self, source_file: str) -> None:
        """Emit the file header comment.

        Args:
            source_file: Name of the source file.

        """
        header = GENERATED_HEADER.format(source_file=source_file)
        for line in header.rstrip().split("\n"):
            self._emitter.emit_raw(line)

    def _emit_imports(self) -> None:
        """Emit the required imports."""
        for line in IMPORTS.rstrip().split("\n"):
            self._emitter.emit_raw(line)

        # Add Pydantic imports if schemas are defined
        if self._schemas:
            self._emitter.emit_raw("from pydantic import BaseModel, create_model")

        self._emitter.emit_blank()

    def _emit_class_definition(self, source_file: str) -> None:
        """Emit the workflow class definition.

        Args:
            source_file: Name of the source file.

        """
        # Generate class name from source file
        class_name = self._generate_class_name(source_file)

        self._emitter.emit(f"class {class_name}(DslAgentWorkflow):")
        self._emitter.indent()

        # Class docstring
        self._emitter.emit(f'"""Generated workflow from {source_file}."""')
        self._emitter.emit_blank()

        # Emit class attributes (schemas before prompts so models are defined)
        self._emit_models()
        self._emit_schemas()
        self._emit_prompts()
        self._emit_tools()
        self._emit_agents()

        # Emit event handlers
        handler_visitor = HandlerVisitor(self._emitter)
        for handler in self._handlers:
            handler_visitor.visit(handler)

        # Emit flow methods
        agents_by_name = {a.name: a for a in self._agents if a.name}
        flow_visitor = FlowVisitor(self._emitter, agents=agents_by_name)
        for flow in self._flows:
            flow_visitor.visit(flow)

        # If no methods emitted, add pass
        if not self._handlers and not self._flows:
            self._emitter.emit("pass")

        self._emitter.dedent()

    def _generate_class_name(self, source_file: str) -> str:
        """Generate a class name from the source file name.

        Args:
            source_file: Name of the source file.

        Returns:
            Pascal case class name.

        """
        # Extract base name without extension
        name = source_file.replace(".sr", "").replace("/", "_").replace(".", "_")

        # Convert to PascalCase
        parts = name.replace("-", "_").split("_")
        pascal_name = "".join(part.capitalize() for part in parts if part)

        return f"{pascal_name}Workflow"

    def _emit_models(self) -> None:
        """Emit the _models class attribute."""
        if not self._models:
            self._emitter.emit("_models: dict[str, str] = {}")
            self._emitter.emit_blank()
            return

        self._emitter.emit("_models = {")
        self._emitter.indent()

        for model in self._models:
            source_line = model.meta.line if model.meta else None
            if model.provider_model:
                self._emitter.emit(
                    f"'{model.name}': '{model.provider_model}',",
                    source_line=source_line,
                )
            elif model.properties:
                # Long form model - emit as dict
                props = model.properties
                provider = props.get("provider", "")
                self._emitter.emit(
                    f"'{model.name}': '{provider}',",
                    source_line=source_line,
                )

        self._emitter.dedent()
        self._emitter.emit("}")
        self._emitter.emit_blank()

    def _emit_schemas(self) -> None:
        """Emit schema definitions as Pydantic create_model() calls."""
        if not self._schemas:
            # Use generic dict type when no schemas to avoid importing BaseModel
            self._emitter.emit("_schemas: dict[str, type] = {}")
            self._emitter.emit_blank()
            return

        # Emit each schema as a create_model() call at module level
        # These are emitted INSIDE the class but as class-level variables
        for schema in self._schemas:
            source_line = schema.meta.line if schema.meta else None
            self._emitter.emit(
                f"{schema.name} = create_model(",
                source_line=source_line,
            )
            self._emitter.indent()
            self._emitter.emit(f'"{schema.name}",')

            for field in schema.fields:
                type_str = self._type_expr_to_string(field.type_expr)
                default = "None" if field.type_expr.is_optional else "..."
                self._emitter.emit(f"{field.name}=({type_str}, {default}),")

            self._emitter.dedent()
            self._emitter.emit(")")
            self._emitter.emit_blank()

        # Emit _schemas class attribute mapping names to models
        self._emitter.emit("_schemas: dict[str, type[BaseModel]] = {")
        self._emitter.indent()

        for schema in self._schemas:
            self._emitter.emit(f'"{schema.name}": {schema.name},')

        self._emitter.dedent()
        self._emitter.emit("}")
        self._emitter.emit_blank()

    def _type_expr_to_string(self, type_expr: TypeExpr) -> str:
        """Convert TypeExpr to Python type string for code generation.

        Args:
            type_expr: DSL type expression.

        Returns:
            Python type annotation as string (e.g., 'str', 'list[str]', 'list[Chunk]').

        """
        # Map DSL primitive types to Python type strings
        type_map = {
            "string": "str",
            "int": "int",
            "float": "float",
            "bool": "bool",
        }

        # Check if it's a primitive type or a custom schema type
        base_type = type_expr.base_type
        if base_type in type_map:
            base = type_map[base_type]
        else:
            # Custom type (schema reference) - use the schema name directly
            # Schema classes are defined in the same scope
            schema_names = {s.name for s in self._schemas}
            # Schema reference or unknown type (default to str)
            base = base_type if base_type in schema_names else "str"

        result = f"list[{base}]" if type_expr.is_list else base

        if type_expr.is_optional:
            result = f"{result} | None"

        return result

    def _emit_prompts(self) -> None:
        """Emit the _prompts class attribute."""
        if not self._prompts:
            self._emitter.emit("_prompts: dict[str, PromptSpec] = {}")
            self._emitter.emit_blank()
            self._emitter.emit("_prompt_models: dict[str, str] = {}")
            self._emitter.emit_blank()
            return

        self._emitter.emit("_prompts = {")
        self._emitter.indent()

        for prompt in self._prompts:
            source_line = prompt.meta.line if prompt.meta else None
            # Generate prompt body for variable interpolation
            body = self._process_prompt_body(prompt.body)

            # Build PromptSpec with optional schema and escalation
            needs_multiline = (
                prompt.expecting is not None
                or prompt.escalation_condition is not None
            )

            if needs_multiline:
                # Multi-line format when we have optional arguments
                self._emitter.emit(
                    f"'{prompt.name}': PromptSpec(",
                    source_line=source_line,
                )
                self._emitter.indent()
                self._emitter.emit(f"body=lambda ctx: {body},")
                if prompt.expecting is not None:
                    self._emitter.emit(f"schema='{prompt.expecting}',")
                if prompt.escalation_condition is not None:
                    self._emitter.emit(
                        f"escalation=EscalationSpec("
                        f"op='{prompt.escalation_condition.op}', "
                        f"value='{prompt.escalation_condition.value}'),",
                    )
                self._emitter.dedent()
                self._emitter.emit("),")
            else:
                # Simple single-line format
                self._emitter.emit(
                    f"'{prompt.name}': PromptSpec(body=lambda ctx: {body}),",
                    source_line=source_line,
                )

        self._emitter.dedent()
        self._emitter.emit("}")
        self._emitter.emit_blank()

        # Emit prompt model associations
        prompts_with_models = [p for p in self._prompts if p.model]
        if not prompts_with_models:
            self._emitter.emit("_prompt_models: dict[str, str] = {}")
            self._emitter.emit_blank()
            return

        self._emitter.emit("_prompt_models = {")
        self._emitter.indent()

        for prompt in prompts_with_models:
            source_line = prompt.meta.line if prompt.meta else None
            self._emitter.emit(
                f"'{prompt.name}': '{prompt.model}',",
                source_line=source_line,
            )

        self._emitter.dedent()
        self._emitter.emit("}")
        self._emitter.emit_blank()

    def _process_prompt_body(self, body: str) -> str:
        """Process prompt body for variable interpolation.

        Args:
            body: Original prompt body.

        Returns:
            Python expression for the prompt body.

        """
        import re

        # Match $variable or $variable.prop1.prop2 (dotted property access)
        var_pattern = (
            r"\$\{?([a-zA-Z_][a-zA-Z0-9_]*"
            r"(?:\.[a-zA-Z_][a-zA-Z0-9_]*)*)\}?"
        )

        def replace_var(match: re.Match[str]) -> str:
            full_ref = match.group(1)
            parts = full_ref.split(".")
            var_name = parts[0]

            if len(parts) == 1:
                # Simple variable: $name â†’ ctx.resolve('name')
                return "{ctx.resolve('" + var_name + "')}"

            # Dotted access uses resolve_property for safe traversal
            prop_args = ", ".join(f"'{p}'" for p in parts[1:])
            return (
                "{ctx.resolve_property('" + var_name + "', " + prop_args + ")}"
            )

        # Replace variables with f-string expressions
        processed = re.sub(var_pattern, replace_var, body)

        # Escape quotes for the f-string
        processed = processed.replace("\\", "\\\\")

        # Use triple-quoted f-string for multiline
        if "\n" in processed:
            return f'f"""{processed}"""'

        # Single line - use regular f-string
        processed = processed.replace('"', '\\"')
        return f'f"{processed}"'

    def _emit_tools(self) -> None:
        """Emit the _tools class attribute."""
        if not self._tools:
            self._emitter.emit("_tools: dict[str, dict[str, Any]] = {}")
            self._emitter.emit_blank()
            return

        self._emitter.emit("_tools = {")
        self._emitter.indent()

        for tool in self._tools:
            source_line = tool.meta.line if tool.meta else None
            self._emit_single_tool(tool, source_line)

        self._emitter.dedent()
        self._emitter.emit("}")
        self._emitter.emit_blank()

    def _emit_single_tool(self, tool: ToolDef, source_line: int | None) -> None:
        """Emit a single tool definition.

        Args:
            tool: Tool definition node.
            source_line: Source line number for mapping.

        """
        self._emitter.emit(f"'{tool.name}': {{", source_line=source_line)
        self._emitter.indent()

        # Required fields
        self._emitter.emit(f"'type': {tool.tool_type!r},")
        if tool.url:
            self._emitter.emit(f"'url': {tool.url!r},")

        # Auth configuration
        if tool.auth_type and tool.auth_value:
            self._emitter.emit("'auth': {")
            self._emitter.indent()
            self._emitter.emit(f"'type': {tool.auth_type!r},")
            self._emitter.emit(f"'value': {tool.auth_value!r},")
            self._emitter.dedent()
            self._emitter.emit("},")

        # Headers (from long form)
        if tool.headers:
            self._emitter.emit(f"'headers': {tool.headers!r},")

        # Builtin reference
        if tool.builtin_ref:
            self._emitter.emit(f"'builtin_ref': {tool.builtin_ref!r},")

        # Tool reference
        if tool.ref:
            self._emitter.emit(f"'ref': {tool.ref!r},")

        self._emitter.dedent()
        self._emitter.emit("},")

    def _emit_agents(self) -> None:
        """Emit the _agents class attribute."""
        if not self._agents:
            self._emitter.emit("_agents: dict[str, dict[str, Any]] = {}")
            self._emitter.emit_blank()
            return

        self._emitter.emit("_agents = {")
        self._emitter.indent()

        for agent in self._agents:
            source_line = agent.meta.line if agent.meta else None
            name = agent.name or "default"
            tools_str = repr(agent.tools)

            # Start agent dict entry
            self._emitter.emit(f"'{name}': {{", source_line=source_line)
            self._emitter.indent()

            # Required fields
            self._emitter.emit(f"'tools': {tools_str},")
            self._emitter.emit(f"'instruction': '{agent.instruction}',")

            # Optional: sub_agents for delegate pattern
            if agent.delegate:
                sub_agents_str = ", ".join(f"'{a}'" for a in agent.delegate)
                self._emitter.emit(f"'sub_agents': [{sub_agents_str}],")

            # Optional: agent_tools for use pattern
            if agent.use:
                agent_tools_str = ", ".join(f"'{a}'" for a in agent.use)
                self._emitter.emit(f"'agent_tools': [{agent_tools_str}],")

            # Optional: default prompt for agent invocation
            if agent.prompt:
                self._emitter.emit(f"'prompt': '{agent.prompt}',")

            # Optional: default output variable name
            if agent.produces:
                self._emitter.emit(f"'produces': '{agent.produces}',")

            # Optional: description for agent
            if agent.description:
                self._emitter.emit(f"'description': {agent.description!r},")

            self._emitter.dedent()
            self._emitter.emit("},")

        self._emitter.dedent()
        self._emitter.emit("}")
        self._emitter.emit_blank()
