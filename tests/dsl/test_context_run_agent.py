"""Tests for WorkflowContext.run_agent() method.

Test that run_agent properly creates and executes ADK agents
based on the workflow configuration.
"""

from collections.abc import AsyncGenerator
from typing import TYPE_CHECKING
from unittest.mock import MagicMock, patch

import pytest

if TYPE_CHECKING:
    from streetrace.dsl.runtime.context import WorkflowContext


async def empty_async_generator() -> AsyncGenerator[object, None]:
    """Return an empty async generator for mocking."""
    return
    yield  # Make this a generator


class TestRunAgent:
    """Test WorkflowContext.run_agent() method."""

    @pytest.fixture
    def workflow_context(self) -> "WorkflowContext":
        """Create a WorkflowContext with test configuration."""
        from streetrace.dsl.runtime.context import WorkflowContext

        ctx = WorkflowContext()

        # Set up models
        ctx.set_models({
            "main": "anthropic/claude-sonnet",
            "agent": "anthropic/claude-opus",
        })

        # Set up prompts with lambdas (as generated by codegen)
        ctx.set_prompts({
            "greeting": lambda _: "Hello! How can I help you today?",
            "analysis": lambda c: f"Analyze: {c.vars.get('input', '')}",
        })

        # Set up prompt models (which model each prompt uses)
        ctx._prompt_models = {  # noqa: SLF001
            "greeting": "main",
            "analysis": "agent",
        }

        # Set up agents
        ctx.set_agents({
            "default": {
                "instruction": "greeting",
                "tools": ["fs"],
            },
            "analyzer": {
                "instruction": "analysis",
                "tools": [],
            },
        })

        return ctx

    @pytest.mark.asyncio
    async def test_run_agent_looks_up_agent_config(
        self,
        workflow_context: "WorkflowContext",
    ) -> None:
        """run_agent looks up agent configuration by name."""
        # Patch the runner to avoid actual execution
        with (
            patch("google.adk.Runner") as mock_runner_class,
            patch("google.adk.agents.LlmAgent") as mock_llm_agent,
            patch("google.adk.sessions.InMemorySessionService"),
        ):
            mock_runner = MagicMock()
            mock_runner.run_async = MagicMock(return_value=empty_async_generator())
            mock_runner_class.return_value = mock_runner

            mock_agent = MagicMock()
            mock_llm_agent.return_value = mock_agent

            await workflow_context.run_agent("default", "test prompt")

            # Verify LlmAgent was called
            mock_llm_agent.assert_called_once()

    @pytest.mark.asyncio
    async def test_run_agent_passes_args_as_prompt(self) -> None:
        """run_agent passes arguments to the agent execution."""
        from streetrace.dsl.runtime.context import WorkflowContext

        ctx = WorkflowContext()
        ctx.set_models({"main": "test-model"})
        ctx.set_prompts({"instruction": lambda _: "Test instruction"})
        ctx.set_agents({
            "default": {"instruction": "instruction", "tools": []},
        })

        with (
            patch("google.adk.Runner") as mock_runner_class,
            patch("google.adk.agents.LlmAgent"),
            patch("google.adk.sessions.InMemorySessionService"),
        ):
            mock_runner = MagicMock()
            mock_runner.run_async = MagicMock(return_value=empty_async_generator())
            mock_runner_class.return_value = mock_runner

            await ctx.run_agent("default", "my prompt argument")

            # Verify run_async was called with a message containing the prompt
            mock_runner.run_async.assert_called_once()
            call_kwargs = mock_runner.run_async.call_args.kwargs
            assert "new_message" in call_kwargs

    @pytest.mark.asyncio
    async def test_run_agent_returns_final_response(self) -> None:
        """run_agent returns the final response from agent execution."""
        from streetrace.dsl.runtime.context import WorkflowContext

        ctx = WorkflowContext()
        ctx.set_models({"main": "test-model"})
        ctx.set_prompts({"instruction": lambda _: "Test instruction"})
        ctx.set_agents({
            "default": {"instruction": "instruction", "tools": []},
        })

        # Create a mock event that represents a final response
        mock_event = MagicMock()
        mock_event.is_final_response.return_value = True
        mock_event.content = MagicMock()
        mock_event.content.parts = [MagicMock(text="The agent response")]

        async def mock_run_async(
            *_args: object,
            **_kwargs: object,
        ) -> "AsyncGenerator[object, None]":
            yield mock_event

        with (
            patch("google.adk.Runner") as mock_runner_class,
            patch("google.adk.agents.LlmAgent"),
            patch("google.adk.sessions.InMemorySessionService"),
        ):
            mock_runner = MagicMock()
            mock_runner.run_async = mock_run_async
            mock_runner_class.return_value = mock_runner

            result = await ctx.run_agent("default", "test prompt")

            assert result == "The agent response"

    @pytest.mark.asyncio
    async def test_run_agent_uses_correct_model(
        self,
        workflow_context: "WorkflowContext",
    ) -> None:
        """run_agent uses the model specified for the agent's instruction."""
        # The analyzer agent uses "analysis" instruction which maps to "agent" model
        with (
            patch("google.adk.Runner") as mock_runner_class,
            patch("google.adk.agents.LlmAgent") as mock_llm_agent,
            patch("google.adk.sessions.InMemorySessionService"),
        ):
            mock_runner = MagicMock()
            mock_runner.run_async = MagicMock(return_value=empty_async_generator())
            mock_runner_class.return_value = mock_runner

            await workflow_context.run_agent("analyzer", "analyze this")

            # Verify LlmAgent was called with the correct model
            mock_llm_agent.assert_called_once()
            call_kwargs = mock_llm_agent.call_args.kwargs
            assert call_kwargs.get("model") == "anthropic/claude-opus"

    @pytest.mark.asyncio
    async def test_run_agent_with_unknown_agent_returns_none(
        self,
        workflow_context: "WorkflowContext",
    ) -> None:
        """run_agent returns None if agent is not found."""
        result = await workflow_context.run_agent("nonexistent_agent")
        assert result is None

    @pytest.mark.asyncio
    async def test_run_agent_gets_instruction_from_prompt(
        self,
        workflow_context: "WorkflowContext",
    ) -> None:
        """run_agent evaluates the prompt lambda to get instruction."""
        with (
            patch("google.adk.Runner") as mock_runner_class,
            patch("google.adk.agents.LlmAgent") as mock_llm_agent,
            patch("google.adk.sessions.InMemorySessionService"),
        ):
            mock_runner = MagicMock()
            mock_runner.run_async = MagicMock(return_value=empty_async_generator())
            mock_runner_class.return_value = mock_runner

            await workflow_context.run_agent("default", "test")

            # Verify instruction was passed to LlmAgent
            mock_llm_agent.assert_called_once()
            call_kwargs = mock_llm_agent.call_args.kwargs
            assert call_kwargs.get("instruction") == "Hello! How can I help you today?"

    @pytest.mark.asyncio
    async def test_run_agent_falls_back_to_main_model(self) -> None:
        """run_agent falls back to 'main' model if prompt has no model."""
        from streetrace.dsl.runtime.context import WorkflowContext

        ctx = WorkflowContext()
        ctx.set_models({"main": "default-model"})
        ctx.set_prompts({"simple": lambda _: "Simple instruction"})
        # No _prompt_models entry for "simple"
        ctx.set_agents({
            "simple_agent": {"instruction": "simple", "tools": []},
        })

        with (
            patch("google.adk.Runner") as mock_runner_class,
            patch("google.adk.agents.LlmAgent") as mock_llm_agent,
            patch("google.adk.sessions.InMemorySessionService"),
        ):
            mock_runner = MagicMock()
            mock_runner.run_async = MagicMock(return_value=empty_async_generator())
            mock_runner_class.return_value = mock_runner

            await ctx.run_agent("simple_agent", "test")

            # Verify LlmAgent was called with main model
            mock_llm_agent.assert_called_once()
            call_kwargs = mock_llm_agent.call_args.kwargs
            assert call_kwargs.get("model") == "default-model"
