"""Tests for DSL flow execution.

Test that generated flows properly execute with ADK integration
and yield events from agent runs.
"""

from collections.abc import AsyncGenerator
from typing import TYPE_CHECKING
from unittest.mock import MagicMock, patch

import pytest

if TYPE_CHECKING:
    from streetrace.dsl.runtime.context import WorkflowContext


class TestFlowExecution:
    """Test flow execution basics."""

    @pytest.fixture
    def workflow_context(self) -> "WorkflowContext":
        """Create a WorkflowContext with test configuration."""
        from streetrace.dsl.runtime.context import WorkflowContext

        ctx = WorkflowContext()

        # Set up models
        ctx.set_models({
            "main": "anthropic/claude-sonnet",
            "summarizer": "anthropic/claude-haiku",
        })

        # Set up prompts with lambdas (as generated by codegen)
        ctx.set_prompts({
            "analyze_prompt": lambda c: f"Analyze: {c.vars.get('input_prompt', '')}",
            "summarize_prompt": lambda _: "Summarize the input.",
        })

        # Set up prompt models (which model each prompt uses)
        ctx._prompt_models = {  # noqa: SLF001
            "analyze_prompt": "main",
            "summarize_prompt": "summarizer",
        }

        # Set up agents
        ctx.set_agents({
            "analyzer": {
                "instruction": "analyze_prompt",
                "tools": ["fs"],
            },
            "summarizer": {
                "instruction": "summarize_prompt",
                "tools": [],
            },
        })

        return ctx

    @pytest.mark.asyncio
    async def test_simple_flow_runs_agent(
        self,
        workflow_context: "WorkflowContext",
    ) -> None:
        """A simple flow that runs a single agent should execute properly."""
        # Create a mock event that represents a final response
        mock_event = MagicMock()
        mock_event.is_final_response.return_value = True
        mock_event.content = MagicMock()
        mock_event.content.parts = [MagicMock(text="Analysis result")]

        async def mock_run_async(
            *_args: object,
            **_kwargs: object,
        ) -> AsyncGenerator[object, None]:
            yield mock_event

        with (
            patch("google.adk.Runner") as mock_runner_class,
            patch("google.adk.agents.LlmAgent"),
            patch("google.adk.sessions.InMemorySessionService"),
        ):
            mock_runner = MagicMock()
            mock_runner.run_async = mock_run_async
            mock_runner_class.return_value = mock_runner

            # Run agent and check result
            workflow_context.vars["input_prompt"] = "test input"
            result = await workflow_context.run_agent("analyzer", "test input")

            assert result == "Analysis result"

    @pytest.mark.asyncio
    async def test_flow_variable_passing(
        self,
        workflow_context: "WorkflowContext",
    ) -> None:
        """Flow variables should be properly passed between agent runs."""
        # First agent returns "step1 result"
        mock_event1 = MagicMock()
        mock_event1.is_final_response.return_value = True
        mock_event1.content = MagicMock()
        mock_event1.content.parts = [MagicMock(text="step1 result")]

        # Second agent returns "step2 result"
        mock_event2 = MagicMock()
        mock_event2.is_final_response.return_value = True
        mock_event2.content = MagicMock()
        mock_event2.content.parts = [MagicMock(text="step2 result")]

        call_count = 0

        async def mock_run_async(
            *_args: object,
            **_kwargs: object,
        ) -> AsyncGenerator[object, None]:
            nonlocal call_count
            call_count += 1
            if call_count == 1:
                yield mock_event1
            else:
                yield mock_event2

        with (
            patch("google.adk.Runner") as mock_runner_class,
            patch("google.adk.agents.LlmAgent"),
            patch("google.adk.sessions.InMemorySessionService"),
        ):
            mock_runner = MagicMock()
            mock_runner.run_async = mock_run_async
            mock_runner_class.return_value = mock_runner

            # Simulate flow: $analysis = run agent analyzer
            # $summary = run agent summarizer $analysis
            workflow_context.vars["input_prompt"] = "test input"

            # Step 1: Run analyzer
            result1 = await workflow_context.run_agent("analyzer")
            workflow_context.vars["analysis"] = result1

            # Step 2: Run summarizer with analysis result
            result2 = await workflow_context.run_agent(
                "summarizer", workflow_context.vars["analysis"],
            )
            workflow_context.vars["summary"] = result2

            assert workflow_context.vars["analysis"] == "step1 result"
            assert workflow_context.vars["summary"] == "step2 result"


class TestSequentialFlowExecution:
    """Test sequential flow execution patterns."""

    @pytest.fixture
    def workflow_context(self) -> "WorkflowContext":
        """Create a WorkflowContext for sequential flow tests."""
        from streetrace.dsl.runtime.context import WorkflowContext

        ctx = WorkflowContext()
        ctx.set_models({"main": "test-model"})
        ctx.set_prompts({
            "step1_prompt": lambda _: "Step 1 instruction",
            "step2_prompt": lambda _: "Step 2 instruction",
        })
        ctx.set_agents({
            "step1_agent": {"instruction": "step1_prompt", "tools": []},
            "step2_agent": {"instruction": "step2_prompt", "tools": []},
        })
        return ctx

    @pytest.mark.asyncio
    async def test_sequential_flow_runs_agents_in_order(
        self,
        workflow_context: "WorkflowContext",
    ) -> None:
        """Sequential agents should run in order."""
        execution_order: list[str] = []

        async def create_mock_run_async(
            agent_name: str,
        ) -> AsyncGenerator[object, None]:
            """Create a mock run_async that tracks execution order."""
            execution_order.append(agent_name)
            mock_event = MagicMock()
            mock_event.is_final_response.return_value = True
            mock_event.content = MagicMock()
            mock_event.content.parts = [MagicMock(text=f"{agent_name} result")]
            yield mock_event

        with (
            patch("google.adk.Runner") as mock_runner_class,
            patch("google.adk.agents.LlmAgent") as mock_llm_agent,
            patch("google.adk.sessions.InMemorySessionService"),
        ):

            def create_runner_for_agent(**kwargs: object) -> MagicMock:
                mock_runner = MagicMock()
                agent = kwargs.get("agent")
                agent_name = (
                    getattr(agent, "name", "unknown") if agent else "unknown"
                )

                def bound_run_async(
                    **_run_kwargs: object,
                ) -> AsyncGenerator[object, None]:
                    return create_mock_run_async(agent_name)

                mock_runner.run_async = bound_run_async
                return mock_runner

            mock_runner_class.side_effect = create_runner_for_agent

            # Make LlmAgent remember its name
            def create_agent(**kwargs: object) -> MagicMock:
                agent = MagicMock()
                agent.name = kwargs.get("name", "unknown")
                return agent

            mock_llm_agent.side_effect = create_agent

            # Run sequential flow
            result1 = await workflow_context.run_agent("step1_agent")
            result2 = await workflow_context.run_agent("step2_agent")

            assert result1 == "step1_agent result"
            assert result2 == "step2_agent result"
            assert execution_order == ["step1_agent", "step2_agent"]


class TestFlowWithDataTransformation:
    """Test flow execution with data transformations."""

    @pytest.fixture
    def workflow_context(self) -> "WorkflowContext":
        """Create a WorkflowContext for data transformation tests."""
        from streetrace.dsl.runtime.context import WorkflowContext

        ctx = WorkflowContext()
        ctx.set_models({"main": "test-model"})
        ctx.set_prompts({
            "analysis_prompt": lambda _: "Analyze the input",
            "format_prompt": lambda _: "Format the analysis",
        })
        ctx.set_agents({
            "analyzer": {"instruction": "analysis_prompt", "tools": []},
            "formatter": {"instruction": "format_prompt", "tools": []},
        })
        return ctx

    @pytest.mark.asyncio
    async def test_flow_with_data_transformation(
        self,
        workflow_context: "WorkflowContext",
    ) -> None:
        """Flow should handle data transformation between agents."""
        # First agent returns raw data
        mock_event1 = MagicMock()
        mock_event1.is_final_response.return_value = True
        mock_event1.content = MagicMock()
        mock_event1.content.parts = [MagicMock(text='{"key": "value"}')]

        # Second agent returns formatted data
        mock_event2 = MagicMock()
        mock_event2.is_final_response.return_value = True
        mock_event2.content = MagicMock()
        mock_event2.content.parts = [MagicMock(text="Formatted: key=value")]

        call_count = 0

        async def mock_run_async(
            *_args: object,
            **_kwargs: object,
        ) -> AsyncGenerator[object, None]:
            nonlocal call_count
            call_count += 1
            if call_count == 1:
                yield mock_event1
            else:
                yield mock_event2

        with (
            patch("google.adk.Runner") as mock_runner_class,
            patch("google.adk.agents.LlmAgent"),
            patch("google.adk.sessions.InMemorySessionService"),
        ):
            mock_runner = MagicMock()
            mock_runner.run_async = mock_run_async
            mock_runner_class.return_value = mock_runner

            # Step 1: Get raw analysis
            raw_analysis = await workflow_context.run_agent("analyzer", "input data")
            workflow_context.vars["analysis"] = raw_analysis

            # Step 2: Format the analysis
            formatted = await workflow_context.run_agent(
                "formatter", workflow_context.vars["analysis"],
            )
            workflow_context.vars["result"] = formatted

            assert workflow_context.vars["analysis"] == '{"key": "value"}'
            assert workflow_context.vars["result"] == "Formatted: key=value"


class TestExpressionVisitorTokenHandling:
    """Test that ExpressionVisitor properly handles Token edge cases."""

    def test_token_in_expression_raises_error(self) -> None:
        """ExpressionVisitor should raise an error for unhandled Tokens."""
        from lark import Token

        from streetrace.dsl.codegen.visitors.expressions import ExpressionVisitor

        visitor = ExpressionVisitor()
        token = Token("RETURN", "return")

        with pytest.raises(ValueError) as exc_info:
            visitor.visit(token)

        assert "Unhandled Token in expression" in str(exc_info.value)
        assert "RETURN" in str(exc_info.value)

    def test_all_known_expression_types_handled(self) -> None:
        """All known expression node types should be handled."""
        from streetrace.dsl.ast.nodes import (
            BinaryOp,
            FunctionCall,
            ListLiteral,
            Literal,
            NameRef,
            ObjectLiteral,
            PropertyAccess,
            UnaryOp,
            VarRef,
        )
        from streetrace.dsl.codegen.visitors.expressions import ExpressionVisitor

        visitor = ExpressionVisitor()

        # Test each expression type
        var_ref = VarRef(name="test")
        assert visitor.visit(var_ref) == "ctx.vars['test']"

        literal = Literal(value=42, literal_type="int")
        assert visitor.visit(literal) == "42"

        string_literal = Literal(value="hello", literal_type="string")
        assert visitor.visit(string_literal) == '"hello"'

        bool_literal = Literal(value=True, literal_type="bool")
        assert visitor.visit(bool_literal) == "True"

        null_literal = Literal(value=None, literal_type="null")
        assert visitor.visit(null_literal) == "None"

        binary_op = BinaryOp(
            op=">",
            left=VarRef(name="x"),
            right=Literal(value=10, literal_type="int"),
        )
        assert visitor.visit(binary_op) == "(ctx.vars['x'] > 10)"

        unary_op = UnaryOp(op="not", operand=VarRef(name="x"))
        assert visitor.visit(unary_op) == "(not ctx.vars['x'])"

        name_ref = NameRef(name="some_name")
        assert visitor.visit(name_ref) == "some_name"

        list_lit = ListLiteral(elements=[Literal(value=1, literal_type="int")])
        assert visitor.visit(list_lit) == "[1]"

        obj_lit = ObjectLiteral(
            entries={"key": Literal(value="val", literal_type="string")},
        )
        assert '"key": "val"' in visitor.visit(obj_lit)

        prop_access = PropertyAccess(base=VarRef(name="obj"), properties=["field"])
        assert visitor.visit(prop_access) == "ctx.vars['obj']['field']"

        func_call = FunctionCall(name="initial_user_prompt", args=[])
        assert visitor.visit(func_call) == "ctx.vars['input_prompt']"


class TestCodeGenerationForFlows:
    """Test code generation produces correct flow code."""

    def test_generated_flow_code_compiles(self) -> None:
        """Generated flow code should be valid Python by compiling flow.sr."""
        from pathlib import Path

        from streetrace.dsl.ast.transformer import transform
        from streetrace.dsl.codegen.generator import CodeGenerator
        from streetrace.dsl.grammar.parser import ParserFactory
        from streetrace.dsl.runtime.workflow import DslAgentWorkflow

        # Use the actual flow.sr example file
        flow_file = Path("agents/examples/dsl/flow.sr")
        if not flow_file.exists():
            pytest.skip("flow.sr example file not found")

        source = flow_file.read_text()

        # Parse, transform, and generate code
        # Note: we bypass semantic analysis which has a separate bug
        parser = ParserFactory.create()
        tree = parser.parse(source)
        ast = transform(tree)

        generator = CodeGenerator()
        python_code, _ = generator.generate(ast, str(flow_file))

        # Compile the generated Python code to verify it's valid
        bytecode = compile(python_code, str(flow_file), "exec")
        assert bytecode is not None

        # Execute to create the workflow class
        namespace: dict[str, object] = {}
        # Note: This is safe - executing DSL-generated code in tests
        exec(bytecode, namespace)  # noqa: S102

        # Check that the workflow class was created
        workflow_class = None
        for obj in namespace.values():
            is_workflow_subclass = (
                isinstance(obj, type)
                and issubclass(obj, DslAgentWorkflow)
                and obj.__name__ != "DslAgentWorkflow"
            )
            if is_workflow_subclass:
                workflow_class = obj
                break

        assert workflow_class is not None

    def test_flow_return_generates_proper_code(self) -> None:
        """Return statement should generate proper Python return."""
        from streetrace.dsl.ast.nodes import FlowDef, Literal, ReturnStmt
        from streetrace.dsl.codegen.emitter import CodeEmitter
        from streetrace.dsl.codegen.visitors.flows import FlowVisitor

        emitter = CodeEmitter("test.sr")
        visitor = FlowVisitor(emitter)

        flow = FlowDef(
            name="test_flow",
            params=[],
            body=[
                ReturnStmt(value=Literal(value="success", literal_type="string")),
            ],
        )

        visitor.visit(flow)
        code = emitter.get_code()

        assert "async def flow_test_flow" in code
        assert 'return "success"' in code
